{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41a81c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65db8d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted object 1: person: 98.16%\n",
      "predicted object 1: person: 98.85%\n",
      "predicted object 1: person: 99.05%\n",
      "predicted object 1: cell phone: 99.21%\n",
      "predicted object 2: person: 98.67%\n",
      "predicted object 1: cell phone: 99.87%\n",
      "predicted object 2: person: 97.09%\n",
      "predicted object 3: person: 52.67%\n",
      "predicted object 1: cell phone: 99.47%\n",
      "predicted object 2: person: 98.61%\n",
      "predicted object 3: person: 89.11%\n",
      "predicted object 1: person: 94.93%\n",
      "predicted object 2: person: 60.37%\n",
      "predicted object 3: person: 55.35%\n",
      "predicted object 1: person: 99.37%\n"
     ]
    }
   ],
   "source": [
    "# Streaming webcam videos\n",
    "webcam_video_stream = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret,current_frame = webcam_video_stream.read()\n",
    "    img_to_detect = current_frame\n",
    "    # get height and width of image\n",
    "    img_height = img_to_detect.shape[0]\n",
    "    img_width = img_to_detect.shape[1]\n",
    "    \n",
    "    # convert to blob to pass into model\n",
    "    # recommended scale factor is 0.007843 and width, height of blob is 300,300 and mean of 255 is 127.5\n",
    "    img_blob = cv2.dnn.blobFromImage(img_to_detect,swapRB=True, crop=False)\n",
    "    \n",
    "    # Set of 81 class labels in alphabetical order (background + rest of 20 classes)\n",
    "    class_labels = [\"person\",\"bicycle\",\"car\",\"motorbike\",\"aeroplane\",\"bus\",\"train\",\"truck\",\"boat\",\"traffic light\",\"fire hydrant\",\"street sign\",\"stop sign\",\"parking meter\",\"bench\",\"bird\",\"cat\",\"dog\",\"horse\",\"sheep\",\"cow\",\"elephant\",\"bear\",\"zebra\",\"giraffe\",\"hat\",\"backpack\",\"umbrella\",\"shoe\",\"eye glasses\",\"handbag\",\"tie\",\"suitcase\",\"frisbee\",\"skis\",\"snowboard\",\"sports ball\",\"kite\",\"baseball bat\",\"baseball glove\",\"skateboard\",\"surfboard\",\"tennis racket\",\"bottle\",\"plate\",\"wine glass\",\"cup\",\"fork\",\"knife\",\"spoon\",\"bowl\",\"banana\",\"apple\",\"sandwich\",\"orange\",\"broccoli\",\"carrot\",\"hot dog\",\"pizza\",\"donut\",\"cake\",\"chair\",\"sofa\",\"pottedplant\",\"bed\",\"mirror\",\"diningtable\",\"window\",\"desk\",\"toilet\",\"door\",\"tv\",\"laptop\",\"mouse\",\"remote\",\"keyboard\",\"cell phone\",\"microwave\",\"oven\",\"toaster\",\"sink\",\"refrigerator\",\"blender\",\"book\",\"clock\",\"vase\",\"scissors\",\"teddy bear\",\"hair drier\",\"toothbrush\"]\n",
    "    \n",
    "    # Declare list of colors as an array\n",
    "    # Green, Blue, Red, Cyan, Yellow, Purple\n",
    "    # Split based on ',' and for every split, change type to init\n",
    "    # convert that to numpy array to apply color mask to the image numpy array\n",
    "\n",
    "    class_colors = [\"0,255,0\",\"0,0,255\",\"255,0,0\",\"255,255,0\",\"0,255,255\",\"255,0,255\"]\n",
    "    class_colors = [np.array(every_color.split(\",\")).astype(\"int\") for every_color in class_colors]\n",
    "    class_colors = np.array(class_colors)\n",
    "    class_colors = np.tile(class_labels,(15,1))\n",
    "    \n",
    "    # Loading pre-trained model from prototext and Tensorflow files \n",
    "    maskrcnn = cv2.dnn.readNetFromTensorflow('datasets/maskrcnn_buffermodel.pb','datasets/maskrcnn_bufferconfig.txt')\n",
    "    \n",
    "    # Input preprocessed blob into model and pass through the model\n",
    "    maskrcnn.setInput(img_blob)\n",
    "    \n",
    "    # obtain the detection predictions (both box and mask) by the model using forward() method\n",
    "    (obj_detections_boxes, obj_detections_masks) = maskrcnn.forward([\"detection_out_final\",\"detection_masks\"])\n",
    "    \n",
    "    \n",
    "    # Loop over the detections\n",
    "    no_of_detections = obj_detections_boxes.shape[2]\n",
    "\n",
    "    for index in np.arange(0, no_of_detections):\n",
    "        prediction_confidence = obj_detections_boxes[0,0,index,2]\n",
    "        # take only predictions with confidence more than 50%\n",
    "        if prediction_confidence > 0.5:\n",
    "            # get the prediction label\n",
    "            predicted_class_index = int(obj_detections_boxes[0,0,index,1])\n",
    "            predicted_class_label = class_labels[predicted_class_index]\n",
    "            # obtain the bounding box co-ordinates for the actual image from resized image size\n",
    "            bounding_box = obj_detections_boxes[0,0,index,3:7] * np.array([img_width, img_height, img_width, img_height])\n",
    "            (start_x_pt, start_y_pt, end_x_pt, end_y_pt) = bounding_box.astype(\"int\")\n",
    "\n",
    "            # obtain width and height of bounding box\n",
    "            bounding_box_width = end_x_pt-start_x_pt\n",
    "            bounding_box_height = end_y_pt-start_y_pt\n",
    "\n",
    "            # obtain the bounding mask co-ordinates for current detection index\n",
    "            object_mask = obj_detections_masks[index, predicted_class_index]\n",
    "            # resize mask to bounding_box_width and bounding_box_height\n",
    "            object_mask = cv2.resize(object_mask, (bounding_box_width,bounding_box_height))\n",
    "            # minimum threshold value to convert float based mask array to binary\n",
    "            # if true respective values will be true and vice versa\n",
    "            object_mask = (object_mask>0.3)\n",
    "\n",
    "            # slice the image array based on bounding box rectangle which is the roi\n",
    "            object_region_of_interest = img_to_detect[start_y_pt:end_y_pt, start_x_pt:end_x_pt]\n",
    "            # slice the roi array based on the bounding box\n",
    "            object_region_of_interest = object_region_of_interest[object_mask]\n",
    "\n",
    "            # get a random mask color from numpy array of colors\n",
    "            #mask_color = random.choice(class_colors)\n",
    "            mask_color = class_colors[predicted_class_index]\n",
    "\n",
    "            # add a transparent color cover to the region of inertest\n",
    "            roi_color_transparent_cover = ((0.3 * mask_color) + (0.5 * object_region_of_interest)).astype(\"uint8\")\n",
    "            # place the transparent color cover over the actual image\n",
    "            img_to_detect[start_y_pt:end_y_pt, start_x_pt:end_x_pt][object_mask] = roi_color_transparent_cover\n",
    "\n",
    "            # convert the color numpy array as a list and apply text and box\n",
    "            mask_color = [int(c) for c in mask_color]\n",
    "\n",
    "            # Print the prediction in console\n",
    "            predicted_class_label = \"{}: {:.2f}%\".format(class_labels[predicted_class_index],prediction_confidence*100)\n",
    "            print(\"predicted object {}: {}\".format(index+1,predicted_class_label))\n",
    "\n",
    "            # Draw rectangle and text in the image\n",
    "            #cv2.rectangle(img_to_detect, (start_x_pt,start_y_pt), (end_x_pt,end_y_pt), mask_color,2)\n",
    "            cv2.putText(img_to_detect, predicted_class_label, (start_x_pt,start_y_pt-5), cv2.FONT_HERSHEY_COMPLEX, 0.5, mask_color,1)\n",
    "\n",
    "    # Show the output image\n",
    "    #plt.imshow(img_to_detect)\n",
    "\n",
    "    cv2.imshow(\"Detection Output\", img_to_detect)\n",
    "    # terminate while loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# releasing the stream and the camera\n",
    "webcam_video_stream.release()\n",
    "# close all opencv windows\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99d03ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
